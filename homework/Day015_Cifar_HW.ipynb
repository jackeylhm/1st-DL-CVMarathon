{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder(categories='auto')\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 1.4829 - acc: 0.4757\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 1.0474 - acc: 0.6296\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.9110 - acc: 0.6763\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.8220 - acc: 0.7078\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.7526 - acc: 0.7359\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.6729 - acc: 0.7652\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.6068 - acc: 0.7887\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.5250 - acc: 0.8162\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.4605 - acc: 0.8395\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.3911 - acc: 0.8645\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.3319 - acc: 0.8853\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2740 - acc: 0.9049\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2342 - acc: 0.9183\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.2031 - acc: 0.9306\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1717 - acc: 0.9418\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.1570 - acc: 0.9463\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.1342 - acc: 0.9545\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.1187 - acc: 0.9608\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1209 - acc: 0.9590\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.1010 - acc: 0.9651\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0904 - acc: 0.9700\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0981 - acc: 0.9671\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0840 - acc: 0.9717\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.0788 - acc: 0.9725\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0741 - acc: 0.9747\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0756 - acc: 0.9748\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0668 - acc: 0.9777\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0682 - acc: 0.9766\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0782 - acc: 0.9743\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0549 - acc: 0.9815\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 100s 2ms/step - loss: 0.0485 - acc: 0.9834\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0627 - acc: 0.9787\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0544 - acc: 0.9819\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0530 - acc: 0.9829\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0638 - acc: 0.9791\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0434 - acc: 0.9849\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0451 - acc: 0.9849\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0507 - acc: 0.9832\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0468 - acc: 0.9846\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0350 - acc: 0.9882\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 101s 2ms/step - loss: 0.0424 - acc: 0.9864\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0510 - acc: 0.9834 4s - loss: \n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0520 - acc: 0.9832\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0375 - acc: 0.9877\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.0300 - acc: 0.9899\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0387 - acc: 0.9874\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0409 - acc: 0.9866\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0393 - acc: 0.9875\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.0392 - acc: 0.9872\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 113s 2ms/step - loss: 0.0473 - acc: 0.9846\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0342 - acc: 0.9896\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.0285 - acc: 0.9902\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0408 - acc: 0.9871\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0379 - acc: 0.9871\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0303 - acc: 0.9898\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0263 - acc: 0.9913\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0330 - acc: 0.9898\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0371 - acc: 0.9880\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0264 - acc: 0.9914\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0261 - acc: 0.9917\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0286 - acc: 0.9909\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0341 - acc: 0.9888\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0317 - acc: 0.9902\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0282 - acc: 0.9911\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0289 - acc: 0.9909\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0322 - acc: 0.9900\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0283 - acc: 0.9908\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0301 - acc: 0.9904\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0244 - acc: 0.9921\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0256 - acc: 0.9920\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.0228 - acc: 0.9926\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0253 - acc: 0.9924\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0224 - acc: 0.9937\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 113s 2ms/step - loss: 0.0225 - acc: 0.9929\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 103s 2ms/step - loss: 0.0262 - acc: 0.9923\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 102s 2ms/step - loss: 0.0233 - acc: 0.9928\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0195 - acc: 0.9940\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 110s 2ms/step - loss: 0.0253 - acc: 0.9927\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 108s 2ms/step - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 118s 2ms/step - loss: 0.0183 - acc: 0.9944\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0269 - acc: 0.9908\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0218 - acc: 0.9935\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0194 - acc: 0.9940\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.0166 - acc: 0.9946\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 109s 2ms/step - loss: 0.0271 - acc: 0.9918\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 0.0252 - acc: 0.9922\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 106s 2ms/step - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0148 - acc: 0.9956\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 104s 2ms/step - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 105s 2ms/step - loss: 0.0230 - acc: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c8b646a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3,3), input_shape=(32,32,3), activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "#classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3,3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "#classifier.add(Dense('自己設計FC層參數')) #output_dim=100,activation=relu\n",
    "classifier.add(Dense(units=100, activation='relu')) \n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5188237e-11, 3.3006562e-32, 4.2907053e-23, 1.0000000e+00,\n",
       "        2.6009280e-14, 0.0000000e+00, 3.6963075e-16, 5.7652580e-38,\n",
       "        2.8377478e-15, 6.1796451e-18]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
